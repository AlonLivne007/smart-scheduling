---
# ğŸ”¬ Smart Scheduling - Deep Dive Internals
## ×”×¡×‘×¨ ×˜×›× ×™ ××¢××•×§ ×œ"××” ×§×•×¨×” ×‘×“×™×•×§ ×ª×—×ª ×”×”×•×“"
---

# **TOPIC 1: Celery & Redis - ×¢×•××§ ××›×× ×™**

## 1. SERIALIZATION - ××” ×§×•×¨×” ×›××©×¨ ×§×•×¨××™× `task.delay(run_id=123)`?

### ğŸ” ×ª×”×œ×™×š ×¤×¢×-××—×¨-×¤×¢×:

```python
# ×§×•×“ ×‘Frontend:
response = requests.post("/api/optimize", json={"weekly_schedule_id": 456})

# ×§×•×“ ×‘Backend:
@app.post("/api/optimize")
async def optimize(data: OptimizeRequest):
    task = run_optimization_task.delay(run_id=456)  # â† ×›××Ÿ ×§×•×¨×” ×”×›×™×©×•×£!
    return {"task_id": task.id}
```

### ğŸ“¦ ×ª×”×œ×™×š ×”Serialization:

```
×©×œ×‘ 1: Python Object
  run_id = 456  (int ×‘×–×™×›×¨×•×Ÿ)

×©×œ×‘ 2: Serialization (Python â†’ JSON)
  Celery + Python-MIP ×‘×ª×¦×•×¨×” ×‘×¨×™×¨×ª ××—×“×œ ××©×ª××©×ª ×‘-JSON
  
  run_id=456 â†’
    JSON: "456"  (string ×‘×¤×•×¨××˜ ×˜×§×¡×˜)
  
  ×× ×”×™×• ×œ× ×• complex objects (numpy arrays ×•×›×•'):
    Celery ×”×™×” ×©×•×œ×— pickle (binary format, unsecure!)
    ××• MessagePack (binary, more compact)

×©×œ×‘ 3: Encoding to Bytes
  JSON string "456" â†’
    UTF-8 bytes: b'456'
    (×›×œ character ×‘JSON ×”×•×¤×š ×œ-bytes)

×©×œ×‘ 4: Task Envelope Creation
  Celery ×‘×•× ×” "task message":
  {
    "id": "abc-123-def",
    "task": "backend.app.tasks.run_optimization_task",
    "args": [456],  â† ×”××¨×’×•×× ×˜×™×
    "kwargs": {},
    "exchange": "celery",
    "routing_key": "celery",
    "properties": {
      "correlation_id": "abc-123",
      "reply_to": "celery.reply.queue"
    },
    "headers": {
      "task_id": "abc-123-def",
      "lang": "py",
      "group": null
    }
  }

×©×œ×‘ 5: Serialization ×©×œ ×”Envelope
  ×›×œ ×”-JSON â†’ bytes ×©×•×‘
  
×©×œ×‘ 6: ×œRedis!
```

### ğŸ’¾ ×‘Redis ×¢×›×©×™×•:

```
Redis List (×‘××§×•× Queue):
  Key: "celery"  (default queue name)
  Value: [
    <serialized message 1>,
    <serialized message 2>,
    ...
  ]

Redis actually stores it as:
  LPUSH celery <serialized_bytes>
```

---

## 2. THE BROKER (Redis) - ××‘× ×” × ×ª×•× ×™× ×¡×¤×¦×™×¤×™

### ğŸ”´ Redis Data Structures ×©Celery ××©×ª××©:

```
1ï¸âƒ£ LISTS (×¢×™×§×¨×™ - ×¢×‘×•×¨ Task Queue)
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   
   Key: "celery"  (Queue name)
   Type: List
   
   Redis command: LPUSH celery <task_payload>
   
   ××‘× ×”:
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ celery (List)                    â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚ [0] â†’ {"task": "run_opt...", ... â”‚  â† ×œ××—×•×§ ×¢× RPOP
   â”‚ [1] â†’ {"task": "run_opt...", ... â”‚
   â”‚ [2] â†’ {"task": "run_opt...", ... â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   
   Worker ×¢×•×©×” RPOP (Right Pop) ×‘×œ×•×œ××”
   (××§×‘×œ ××”×§×¦×” ×”×™×× ×™, ××˜×‘×¢×•×ª ××”×©×××œ)

2ï¸âƒ£ HASH MAPS (×¢×‘×•×¨ Task State)
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   
   Key: "celery-task-meta-<task_id>"
   Type: Hash
   
   Value:
   {
     "status": "PENDING",  â†’ ×©×œ××—×¨ ×–××Ÿ: "STARTED", "SUCCESS", "FAILURE"
     "result": null,       â†’ ××—×¨×™ ×‘×“×™×§×”: <actual result>
     "traceback": null,
     "children": [],
     "date_done": null
   }
   
   Frontend ×¢×•×©×” Polling ×›×“×™ ×œ×‘×“×•×§:
   GET celery-task-meta-abc-123-def â†’ {"status": "PENDING"}
   (××—×¨×™ 2 ×©× ×™×•×ª)
   GET celery-task-meta-abc-123-def â†’ {"status": "RUNNING"}
   (××—×¨×™ ×¢×•×“ 30 ×©× ×™×•×ª)
   GET celery-task-meta-abc-123-def â†’ {"status": "SUCCESS", "result": {...}}

3ï¸âƒ£ SETS (×¢×‘×•×¨ Task Acks ×•-Reservations - complex)
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   
   ×›×©Worker ×§×•×¨× task:
     - ××•×¡×™×£ ××ª task_id ×œSET ×©×œ "active tasks"
     - ×× Worker nope ×›××• 5 ×“×§×•×ª ×œ×œ× "heartbeat" â†’ removes automatically
```

### ğŸ“‹ Task Payload ×‘Redis - ××” ×–×” ×œ××¢×©×”?

```json
{
  "body": [
    "[456]",  // args: [run_id=456]
    {},       // kwargs: empty
    {
      "callbacks": null,
      "errbacks": null,
      "chain": null,
      "chord": null
    }
  ],
  "headers": {
    "lang": "py",
    "task": "backend.app.tasks.run_optimization_task",
    "id": "c4f53-8a92-4d21-9e8e-abc123def456",
    "shadow": null,
    "eta": null,
    "expires": null,
    "group": null,
    "retries": 0,
    "timelimit": [3600, 3300],  // Hard limit 1h, Soft 55m
    "parent_id": null,
    "root_id": "c4f53-8a92-..."
  },
  "content-encoding": "utf-8",
  "content-type": "application/json"
}
```

---

## 3. THE WORKER - ××™×š ×”×•× ×™×•×“×¢ ×©×™×© Task?

### ğŸ¤– Worker Loop - ×œ× Busy Wait!

```python
# Celery Worker ×‘×¤×•×¢×œ ×¢×©×” ××©×”×• ×›××•:

def worker_main_loop():
    while True:
        # âŒ ×–×” ×œ× busy wait! 
        # ××“×•×¢? ×›×™ ×–×” ×”×™×” ×‘×–×‘×•×– ××—×•×– CPU
        
        # âœ… ×–×” ××” ×©×××ª ×§×•×¨×”:
        
        # 1. Block on Redis (×ª×©×•××ª ×œ×‘!)
        #    Worker ×¢×•××“ ×‘×—×›×™×™×” ×¢×“ ×©×ª×’×™×¢ task (OS level blocking)
        task = redis.BRPOP("celery", timeout=1)
        #    â†‘ BRPOP = "Blocking Right Pop"
        #    Worker SLEEPS ×¢×“ ×©×™×© ××©×”×• ×‘×ª×•×¨
        
        if task:
            # 2. Mark as started
            update_task_state(task_id, "STARTED")
            
            # 3. Execute
            result = run_optimization_task(task.args[0])
            
            # 4. Mark as done
            update_task_state(task_id, "SUCCESS", result=result)
        else:
            # timeout hit, continue loop
            continue
```

### âš™ï¸ Prefetch Multiplier - ××” ×–×” ×‘×“×™×•×§?

```
×‘×¨×™×¨×ª ××—×“×œ: worker_prefetch_multiplier = 4
(×‘×¤×¨×•×™×§×˜ ×©×œ×š: 1, ×›×™ MaxTasksPerChild = 50)

××” ×–×” ×¢×©×”?

scenario: Queue ×™×© 10 tasks

Prefetch=4:
  Worker ×§×•×¨× 4 tasks ×-Redis ×‘×‘×ª ××—×ª
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Redis      â”‚
  â”‚ Queue [10] â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
  BRPOP x4
         â”‚
         â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Worker Memory      â”‚
  â”‚ [task1, task2,     â”‚
  â”‚  task3, task4] â†   â”‚ In-memory prefetch buffer
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  
  Worker ×¢×•×‘×“ ×¢×œ task1
  ×‘×• ×–×× ×™×ª, ×”×•× ×›×‘×¨ ×§×¨× ××ª 2,3,4 ××”×¨×—×•×‘
  
  Advantages:
    âœ… ×× task1 + task2 ×§×˜× ×™×, Worker ×œ× ×—×•×–×¨ ×œ-Redis
    âœ… × ×™×¦×•×œ ×‘× ×“×•×•×™×“×ª ××”×™×¨ ×™×•×ª×¨
  
  Disadvantages:
    âŒ ×× Worker × ×¤×œ ×¢× task3 ×‘××–×™×›×¨×•×Ÿ = ×”×•× lost (×œ× ×‘-Redis)
    âŒ Memory overhead ×× tasks ×’×“×•×œ×™×

×‘×¤×¨×•×™×§×˜ ×©×œ×š:
  prefetch_multiplier = 1
  â†’ Worker ×§×•×¨× ×¨×§ 1 task ×‘×‘×ª ××—×ª
  â†’ ×™×•×ª×¨ safe (××‘×œ ×§×¦×ª ×™×•×ª×¨ slow)
```

---

## 4. THE "WHY" - Python Thread vs. Celery - ××™×–×” ××©××‘ ×™×¡×ª×™×™× ×¨××©×•×Ÿ?

### ğŸ”¥ Load Test: 100 Users Ã— 300-second Solve

#### Scenario A: Simple Python Threads (âŒ ×’×¨×•×¢)

```python
# ×‘FastAPI ×‘×œ×™ Celery:
@app.post("/optimize")
async def optimize(data):
    # Just call directly!
    result = solver.solve()  # Blocks for 300 seconds
    return result
```

```
×”×‘×¢×™×”:
  - ×›×œ ×‘×§×©×” = × ×•×¦×¨×ª Thread ×‘JVM/OS
  - 100 ×‘×§×©×•×ª ×‘×•-×–×× ×™×ª = 100 threads ×—×¡×•××•×ª
  - ×›×œ thread = ~2MB stack memory (default)
  - Total: 100 * 2MB = 200MB ×¨×§ ×œstacks!
  
  ×× ×”××›×•× ×” ×™×© 4GB RAM:
    Memory limit reached â‰ˆ 2000 threads
    
    But:
    âŒ GIL (Global Interpreter Lock) ×‘Python!
    â†’ ××¤×™×œ×• ×¢× threads, ×¨×§ ××—×“ ×‘×¨×™×¥ ×‘×¤×•×¢×œ
    â†’ 99 threads ×—×•×›×™×
    â†’ Context switches = ×‘×–×‘×•×– CPU
    
    âŒ File Descriptors!
    â†’ ×›×œ connection HTTP = 1 file descriptor (FD)
    â†’ Linux default limit: 1024 FDs per process
    â†’ ××—×¨×™ 1024 connections: "Too many open files" âŒ
```

### ××” ×™×™×¡×ª×™×™× ×¨××©×•×Ÿ?

```
1ï¸âƒ£ File Descriptors (1024) â† ×–×” ×”×¨××©×•×Ÿ! âŒ

   ×›×œ HTTP connection ×¦×•×¨×š 1 FD
   Server crash ×‘-1000 ×‘×§×©×•×ª ×‘×•-×–×× ×™×ª
   
   Error: "OSError: [Errno 24] Too many open files"

2ï¸âƒ£ Memory (2GB for threads)
   100 threads * 2MB = 200MB - ×‘×¡×“×¨
   1000 threads * 2MB = 2GB - OOM Killer kills process
   
3ï¸âƒ£ GIL (Global Lock)
   ×œ× ×‘×“×™×•×§ "runs out" ××‘×œ context switches
   ××•×¨×™×“ throughput ××©××¢×•×ª×™×ª
```

#### Scenario B: Celery + Redis (âœ… ×˜×•×‘)

```
100 ×‘×§×©×•×ª:
  - FastAPI handler: 100ms ×›×œ ××—×ª (non-blocking!)
  - Tasks ×‘-Redis: ××”×“×•×¨×•×ª ×œ×§×• ××—×™×¦×”
  - 4 Celery Workers: ×—×œ×•×§×ª ×”×¢×‘×•×“×”
  
  Memory:
    - FastAPI: ~100MB (constant)
    - 4 Worker processes: 4 * 300MB = 1.2GB
    - Redis: ~100MB
    Total: ~1.4GB (predictable!)
  
  File Descriptors:
    - FastAPI: ~20-50 FDs
    - Redis: ~10 FDs
    - Workers: ~5 FDs each * 4 = 20 FDs
    Total: ~100 FDs (××ª×—×ª ×œ×’×‘×•×œ ×©×œ 1024)
  
  GIL:
    - âŒ ×›×œ Worker ×ª×”×œ×™×š ××©×œ×• (separate Python interpreter)
    - âœ… ××™×Ÿ GIL ×‘×™×Ÿ processes (×¨×§ ×‘×ª×•×š)
    - âœ… True parallelism!
```

---

---

# **TOPIC 2: MIP Solver Black Box - Branch and Bound**

## 1. The Search Tree - Branch and Bound (B&B)

### ğŸ“Š ×”××¨××” ×”×›×œ×œ×™:

```
×‘×¢×™×”: ×”×§×¦×” 50 ×¢×•×‘×“×™× Ã— 100 ××©××¨×•×ª Ã— 5 ×ª×¤×§×™×“×™×

×× × ×©×ª××© ×‘Brute Force:
  - ××¡×¤×¨ ××©×ª× ×™×: 50 * 100 * 5 = 25,000 ×‘×™× ××¨×™×
  - Combinations: 2^25000 (×›×œ×•××¨... ×ª×•×š 10^7000 ×©× ×™×•×ª)
  - âŒ ×‘×œ×ª×™ ××¤×©×¨×™

×¤×ª×¨×•×Ÿ: Branch and Bound!
  - ×¡×“×¨ ×—×™×¤×•×© ×—×›×
  - ×’×™×–×•× (Pruning) ×©×œ ×¢× ×¤×™× ×—×¡×¨×™ ×ª×§×•×•×”
```

### ğŸŒ³ ×“×•×’××” ×§×˜× ×” - 3 ××©×ª× ×™× ×‘×™× ××¨×™×™×

```
××˜×¨×”: Maximize: 2*x1 + 3*x2 + x3 (×›××©×¨ x1,x2,x3 âˆˆ {0,1})

×©×œ×‘ 1: Linear Relaxation (treat as continuous)
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  x1, x2, x3 âˆˆ [0, 1] (continuous)
  
  Solution: x1=1, x2=1, x3=1 â†’ Objective = 2 + 3 + 1 = 6
  (×× ×”×™×• ×§×™×™××™× ××™×œ×•×¦×™× × ×•×¡×¤×™×, ×”×™×™× ×• ×§×¦×ª ×¤×—×•×ª ×-6)

  ×–×” **Upper Bound** = 6
  â†’ ×× ×—× ×• ×™×•×“×¢×™× ×©×”×¤×ª×¨×•×Ÿ ×”×©×œ× ×œ×¢×•×œ× ×œ× ×™×¢×œ×” ×¢×œ 6

×©×œ×‘ 2: Branch on x1
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  
           [Root: UB=6]
           /         \
        /               \
  [x1=0]              [x1=1]
  UB=4.5              UB=5.8
    /                   /
   /                    \
Branch on x2          Branch on x2
(x1=0)                (x1=1)
     
×©×œ×‘ 3: Solve each subproblem
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  
  Subproblem: x1=0, x2=1, x3âˆˆ[0,1]
    Objective â‰¤ 0 + 3 + 1 = 4 (Upper Bound)
    â†’ ×× ×× ×—× ×• ×›×‘×¨ ××¦×× ×• ×¤×ª×¨×•×Ÿ ×¢× 4, prune!
    
  Subproblem: x1=1, x2=1, x3=0
    Objective = 2 + 3 + 0 = 5 (Integer feasible!)
    â†’ ×–×” ×¤×ª×¨×•×Ÿ ×—×•×§×™, update best found = 5

×©×œ×‘ 4: Pruning
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  
  ×× ×©× ×™ × ×•×›×œ:
    - ××¦×× ×• ×‘×¨ = 5
    - Branch ×‘×Ÿ ×™×© Upper Bound = 4.5
    
  â†’ PRUNE! ×œ×¢×•×œ× ×œ× ×ª×•×›×œ ×œ×”×™×•×ª ×˜×•×‘ ×-5
```

### ğŸ”ª Pruning Rules (×™×¡×•×“ ×”××”×™×¨×•×ª!)

```
×›×œ×œ 1: Bound Pruning
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  ×× Upper Bound ×©×œ Branch < Best Found So Far
  â†’ Prune (×œ×¢×•×œ× ×œ× ×ª×•×›×œ ×œ×”×™×•×ª ×”×”×¦×¢×” ×”×˜×•×‘×” ×‘×™×•×ª×¨)

×›×œ×œ 2: Infeasibility Pruning
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  ×× ×”sub-problem ×”×•× INFEASIBLE
  â†’ Prune (××™×Ÿ ×¤×ª×¨×•×Ÿ ×›××Ÿ)

×›×œ×œ 3: Integrality Pruning
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  ×× ×›×œ ×”××©×ª× ×™× ×‘×¤×ª×¨×•×Ÿ ×”× ×›×‘×¨ 0 ××• 1
  â†’ ×™×© ×œ× ×• ×¤×ª×¨×•×Ÿ ×©×œ×! Save it, don't branch further
```

---

## 2. Linear Relaxation - ×œ××” ×–×” ×˜×¨×™×§ ×××™×ª×™?

### ğŸ”“ ××” ×§×•×¨×” ×›×©××ª×¢×œ××™× ××”××’×‘×œ×” ×©×œ "×‘×™× ××¨×™"?

```
×‘×¢×™×” ××§×•×¨×™×ª:
  max: 2*x1 + 3*x2 + x3
  s.t.
    x1 + x2 <= 1.5  (constraint)
    x1, x2, x3 âˆˆ {0, 1}  (binary!)

Linear Relaxation:
  max: 2*x1 + 3*x2 + x3
  s.t.
    x1 + x2 <= 1.5
    x1, x2, x3 âˆˆ [0, 1]  (continuous!)
    
  Relaxed Solution:
    x1 = 0.5, x2 = 1, x3 = 1
    Objective = 2*0.5 + 3*1 + 1 = 5.5
    
  ×–×” Upper Bound!
  â†’ ×¤×ª×¨×•×Ÿ ×©×œ× ×œ×¢×•×œ× ×œ× ×™×¢×œ×” ×¢×œ 5.5
```

### ğŸ¯ ×œ××” ×–×” ××”×™×¨?

```
1. Linear Programs ×”× ×§×œ×™× ×œ×¤×ª×•×¨!
   â†’ Simplex Algorithm ×™×›×•×œ ×œ×¤×ª×•×¨ ×‘×©× ×™×•×ª
   â†’ ××¤×™×œ×• ×¢× 1 ××™×œ×™×•×Ÿ ××©×ª× ×™×!

2. Upper Bound ××™×“ ××•×¢×™×œ!
   - ×¢× Upper Bound = 5.5
   - ×× ×× ×—× ×• ××¦×× ×• ×¤×ª×¨×•×Ÿ ×‘×Ÿ 5
   - ×× ×—× ×• ×™×•×“×¢×™×: optimal âˆˆ [5, 5.5]
   - ×”×¤×¢×¨ ×”×•× ×§×˜×Ÿ!
   
   ×× ×¢×“×™×™×Ÿ ×œ× ××¦×× ×• ×¤×ª×¨×•×Ÿ:
   - × ×™×ª×Ÿ ×œ×”××©×™×š ×œ×‘×“×•×§ ×¨×§ branches ×¢× potential

3. Pruning ×˜×•×‘ ×™×•×ª×¨!
   - ×™×•×ª×¨ branches ××•×¤×©×œ×•×ª
   - ×”×—×™×¤×•×© ×¢×¥ ×”×•× ×§×˜×Ÿ ×™×•×ª×¨
```

---

## 3. Mathematical Equation - No Overlap Constraint

### ğŸ“ ×¢×‘×•×¨ ××©××¨×•×ª ×—×•×¤×¤×•×ª, ××©×ª× ×” ×™×—×™×“

```
×ª×¨×’×•× ×Python ×œ-Math:

# Python:
for emp in employees:
    for shift1, shift2 in overlapping_pairs:
        for role in roles:
            if (emp, shift1, role) in x and (emp, shift2, role) in x:
                model += x[(emp, shift1, role)] + x[(emp, shift2, role)] <= 1

# Math (×¢×‘×•×¨ ×¢×•×‘×“ specific i, ×ª×¤×§×™×“ specific r):

âˆ‘_{sâˆˆS_overlapping(shift1)} x_{i,s,r} + x_{i,shift1,r} â‰¤ 1

××• ×‘×“×¨×š ×™×•×ª×¨ ×¤×©×•×˜×” ×œ×©×ª×™ ××©××¨×•×ª ×—×•×¤×¤×•×ª:

x_{i, shift1, r} + x_{i, shift2, r} â‰¤ 1

×›××©×¨:
  i = employee index
  shift1, shift2 = overlapping shift indices
  r = role id
  x_{i,j,r} âˆˆ {0, 1} = binary variable
```

### ×× ×™×© N overlapping shifts:

```
×¢×‘×•×¨ ×¢×•×‘×“ ×•××©××¨×•×ª ××¨×•×‘×•×ª ×©×—×•×¤×¤×•×ª ×‘×—×œ×§×Ÿ:

âˆ‘_{j âˆˆ shifts_that_overlap_with_shift1} x_{i,j,r} â‰¤ 1

×–×” ××•×•×“×: ×¢×•×‘×“ ×™×›×•×œ ×œ×”×™×•×ª ×‘×œ×›×œ ×”×™×•×ª×¨ 1 ××”××©××¨×•×ª ×”×—×•×¤×¤×•×ª
```

---

## 4. Pruning Logic - Score 100 vs. UB 80

### ğŸ¯ ×”-Moment of Truth:

```
Scenario:
  - Best solution found so far: Score = 100
  - Current branch being explored:
    * Relaxation gives UB = 80
    * (×›×œ×•××¨, ××¤×™×œ×• ×‘×¢×•×œ× ××•×©×œ×, 80 ×”×•× ×”××§×¡×™××•×)

Logic:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ if (current_branch_UB < best):  â”‚
  â”‚   PRUNE this entire branch!     â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  
  ×›××Ÿ:
    UB = 80
    best = 100
    80 < 100? YES!
    
    â†’ PRUNE!
    
  ××“×•×¢?
    - ×–×” impossible ×©× ××¦× ××©×”×• ×˜×•×‘ ×™×•×ª×¨ ×-100 ×‘×‘ranch ×–×”
    - ×›×œ ×”×™×œ×“×™× ×©×œ branch ×–×” ×™×”×™×• ×‘×˜×— ×¢× score â‰¤ 80
    - ×›×œ ×¢×‘×•×“×” × ×•×¡×¤×ª ×›××Ÿ ×”×™× ×‘×–×‘×•×–
```

### ğŸ“Š ×“×•×’××” ×¢× ×¡×¤×™×¨×”:

```
×‘×œ×™ Pruning:
  2^n ××¤×©×¨×•×™×•×ª = 2^25000 (×œ×“×•×’××”)
  Time: âˆ ×©× ×™×•×ª

×¢× Pruning (×ª×§×¦×™×¨):
  Start: 100 branches
  â†“ (×œ××—×¨ Linear Relaxation ×©×œ ×›×œ ××—×“)
  â†“ Prune 70 branches (UB < best)
  â†“ Explore 30 branches further
  â†“ Branch further: 30 * 2 = 60
  â†“ Prune 50: 10 remain
  â†“ ... iterate until convergence
  
  Final explored: ~150-200 nodes (×× ×”parameters ×˜×•×‘×™×)
  
  Time: ×©× ×™×•×ª ×¢×“ ×“×§×•×ª (×‘×¢×§×•× ×©×‘×—×¨× ×•)!
```

---

---

# **TOPIC 3: Application Stack - Pydantic, ORM, Database**

## 1. Pydantic vs. Dict - ×œ××” Schemas?

### ğŸ†š ×”×©×•×•××”:

```python
# âŒ ×œ×œ× Pydantic (Just Dicts):
@app.post("/optimize")
def optimize(data: dict):
    run_id = data["weekly_schedule_id"]
    # ×‘×¢×™×•×ª:
    # - run_id could be "not a number" â†’ string!
    # - data could be {"random_field": 123}
    # - No type checking
    # - No IDE autocomplete

# âœ… ×¢× Pydantic:
from pydantic import BaseModel

class OptimizeRequest(BaseModel):
    weekly_schedule_id: int

@app.post("/optimize")
def optimize(data: OptimizeRequest):
    run_id = data.weekly_schedule_id  # âœ… guaranteed int!
```

### ğŸ“‹ Data Parsing vs. Validation:

```
PARSING (×××™×¨ ×¡×•×’×™×):
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  
  JSON Input:
    {"weekly_schedule_id": "456"}  â† string!
  
  Pydantic Parsing:
    "456" (string) â†’ 456 (int)
    
  Explicit Coercion Rules:
    "456" â†’ int("456") â†’ 456 âœ…
    "abc" â†’ int("abc") â†’ ValueError âŒ
    456 (already int) â†’ 456 âœ…

VALIDATION (×‘×•×“×§ × ×›×•× ×•×ª):
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  
  After parsing (data is already correct type):
    weekly_schedule_id = 456 (int)
  
  Validators can check:
    - Is 456 a valid weekly_schedule_id? (exists in DB?)
    - Is 456 > 0? (positive?)
    - Is 456 < 1000000? (reasonable range?)
    
  Example:
    class OptimizeRequest(BaseModel):
        weekly_schedule_id: int
        
        @field_validator('weekly_schedule_id')
        def validate_schedule(cls, v):
            if v < 1:
                raise ValueError('Must be positive')
            return v
```

### ğŸ”¥ Runtime Behavior - String to Int:

```python
# Frontend sends:
json_data = {"weekly_schedule_id": "456"}

# Backend FastAPI:
request = OptimizeRequest(**json_data)

# Step-by-step in Pydantic:
1. Parse JSON string "456" â†’ Python object {"weekly_schedule_id": "456"}
2. Check schema: weekly_schedule_id is int, got str
3. Try coerce: int("456") â†’ 456
4. Success! request.weekly_schedule_id = 456 (now int)

# If it was invalid:
json_data = {"weekly_schedule_id": "not_a_number"}

1. Parse JSON â†’ {"weekly_schedule_id": "not_a_number"}
2. Check schema: int expected, got str
3. Try coerce: int("not_a_number") â†’ ValueError
4. Pydantic catches: raises ValidationError
5. FastAPI returns: HTTP 422 Unprocessable Entity
   {
     "detail": [
       {
         "type": "value_error",
         "loc": ["body", "weekly_schedule_id"],
         "msg": "value is not a valid integer"
       }
     ]
   }
```

---

## 2. SQLAlchemy - Session & Transaction (ACID)

### ğŸ”„ ××” ×§×•×¨×” ×¢× `db.add(model)`?

```python
# Code:
session = SessionLocal()
run = SchedulingRunModel(
    weekly_schedule_id=456,
    status="PENDING"
)
session.add(run)  # â† What happens?
session.commit()
```

### Step-by-step:

```
×©×œ×‘ 1: session.add(run)
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  
  âœ… Add to session's identity map
  â””â”€ session._identity_map[id(run)] = run
  
  âœ… Mark as "pending" (not yet in DB)
  â””â”€ run._sa_instance_state.persistent = False
  
  âŒ NOT in database yet!
  â””â”€ No SQL executed!
  
  ×–×” ×—×™×–×•×™ ×‘×œ×‘×“ ×©×œ memory

×©×œ×‘ 2: session.commit()
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  
  âœ… Session flush (×™×™×¦×•× ×œDB)
    INSERT INTO scheduling_run (weekly_schedule_id, status)
    VALUES (456, 'PENDING')
    RETURNING id;
  
  âœ… Commit transaction
    COMMIT;
  
  âœ… Mark as persistent
    run._sa_instance_state.persistent = True
    run.id = <generated_id>
  
  × ×ª×•× ×™× ×‘DB!
```

### ğŸ“Š Transaction & ACID:

```
ACID = Atomicity, Consistency, Isolation, Durability

×‘×”×§×©×¨ ×©×œ× ×• (scheduling):

ATOMICITY:
  â”€â”€â”€â”€â”€â”€
  
  ×›××©×¨ ×× ×—× ×• ×™×•×¦×¨×™× SchedulingRun ×•×›×œ SchedulingSolutions:
  
  transaction = [
    INSERT INTO scheduling_run (status) VALUES ('PENDING'),
    INSERT INTO scheduling_solution (run_id, user_id, ...) VALUES (...),
    INSERT INTO scheduling_solution (run_id, user_id, ...) VALUES (...),
    ... 1000 more inserts ...
  ]
  
  commit();
  
  ×× ×”×§×•×‘×¥ ×•×”-1001 insert × ×›×©×œ:
    â†’ Entire transaction rolled back
    â†’ 0 ×©×•×¨×•×ª ×‘DB
    â†’ No orphan records
    
  ××“×•×¢ ×–×” critical ×œScheduling?
    - SchedulingRun ×œ×œ× Solutions = ×—×¡×¨ ××˜×¨×”
    - Solutions ×œ×œ× Run = orphaned data
    - Atomicity = ××• ×›×œ ××• ×›×œ×•×!

CONSISTENCY:
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  
  Foreign keys enforced:
    INSERT INTO scheduling_solution (run_id, user_id, ...)
    VALUES (999, 888, ...)
    
  ×× run_id=999 ×œ× ×§×™×™× â†’ ERROR! (FK violation)
  
  Constraints enforced:
    MAX_HOURS_PER_WEEK must be valid
    UNIQUE constraints honored

ISOLATION:
  â”€â”€â”€â”€â”€â”€â”€
  
  ×× 2 users ×œ×•×§×—×•×ª optimization ×‘×•-×–×× ×™×ª:
  
  User A: SELECT weekly_schedule_id=1
  User B: SELECT weekly_schedule_id=1
  
  ×¢× ACID isolation:
    - User A ×‘×˜×•×— ×©B ×œ× ×™×¢×“×›×Ÿ ××ª ×–×” ×‘×¢××¦×¢
    - ×›×œ Transaction ×‘×‘×“×“×• (even if concurrent)

DURABILITY:
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  
  ××—×¨×™ COMMIT:
    - × ×ª×•× ×™× ×›×ª×•×‘×™× ×œ×“×™×¡×§
    - ××¤×™×œ×• ×× server crashing, data survives
    - Recovery ×Power Loss ××•×‘×˜×—
```

---

## 3. PostgreSQL vs. NoSQL (Mongo) - ×œ××” Relational?

### ğŸ†š ×”×”×©×•×•××”:

```
SCHEDULING REQUIREMENTS:

1. Complex Relations
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   
   User â† has many â†’ Role
   User â† works â†’ Shift
   Shift â† requires â†’ Role
   User â† has-preferences â†’ Shift
   
   SQL (Joins):
     SELECT u.name, s.date, r.name
     FROM users u
     JOIN scheduling_solution ss ON u.id = ss.user_id
     JOIN planned_shift s ON ss.planned_shift_id = s.id
     JOIN role r ON ss.role_id = r.id
     WHERE s.weekly_schedule_id = 456;
   
   (Clean, Declarative)
   
   MongoDB (Embedded/References):
     db.users.find({...}).aggregate([
       {$lookup: {from: "scheduled", ...}},
       {$lookup: {from: "shifts", ...}},
       ...
     ])
   
   (Complex, verbose)

2. Data Integrity (FOREIGN KEYS)
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   
   SQL:
     ALTER TABLE scheduling_solution
     ADD CONSTRAINT fk_user
     FOREIGN KEY (user_id)
     REFERENCES users(id)
     ON DELETE RESTRICT;
   
   â†’ Database enforces:
     Can't delete user if they have assignments!
   
   MongoDB:
     No enforced FKs!
     â†’ Data corruption possible:
       {user_id: 999} but user 999 doesn't exist
   
   â†’ Application must handle (error-prone)

3. ACID Transactions
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   
   SQL (Multi-row):
     BEGIN;
     INSERT INTO scheduling_run ...
     INSERT INTO scheduling_solution ... (1000 rows)
     COMMIT;
   
   â†’ All or nothing guarantee
   
   MongoDB:
     Single-document ACID (limited)
     Multi-document ACID (added in 4.0+, less mature)
   
   â†’ Risk of partial failures

4. Querying Flexibility
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   
   Questions we ask:
     - Find all employees assigned to shift X
     - Find all shifts a user is assigned to
     - Find overlaps
     - Aggregate hours per employee
   
   SQL:
     SELECT * FROM scheduling_solution
     WHERE planned_shift_id = 456;
     
     (1 query, very fast)
   
   MongoDB:
     db.scheduling_solution.find({
       planned_shift_id: ObjectId("...")
     })
     
     (OK, but embedded docs make it harder)

CONCLUSION:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

âœ… PostgreSQL ×“×•×‘×¨×ª:
  - Complex relationships (many JOINs)
  - Strong consistency (ACID)
  - Referential integrity
  - This is relational data!

âŒ MongoDB ×¢×“×™×£:
  - Flexible schema (but ours is fixed!)
  - Horizontal scaling (we don't need, single DB)
  - Document querying (document structure not ideal for scheduling)
```

### ğŸ“Š Schema Comparison:

```
POSTGRES (Relational - Normalized):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

TABLE users:
  id INT PRIMARY KEY
  name VARCHAR
  roles INT[] (array of role IDs)

TABLE scheduling_solution:
  id INT PRIMARY KEY
  run_id INT FOREIGN KEY â†’ scheduling_run
  user_id INT FOREIGN KEY â†’ users
  shift_id INT FOREIGN KEY â†’ planned_shift
  role_id INT FOREIGN KEY â†’ roles

Queries are clean:
  SELECT COUNT(*) FROM scheduling_solution
  WHERE user_id = 123 AND role_id = 1;

MONGODB (Document - Denormalized):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Document structure:
  db.scheduling_solutions.insertOne({
    _id: ObjectId(...),
    run: {
      id: 1,
      status: "PENDING",
      started_at: Date(...),
      config: { weight_fairness: 0.5, ... }
    },
    user: {
      id: 123,
      name: "John",
      roles: [1, 2, 3]
    },
    shift: {
      id: 456,
      date: Date(...),
      start: Time(...),
      end: Time(...)
    },
    role: {
      id: 1,
      name: "Waiter"
    }
  })

Queries are verbose:
  db.scheduling_solutions.find({
    "user.id": 123,
    "role.id": 1
  }).count()

Problems:
  - If user 123 is updated, every document with that user needs update
  - Data duplication + consistency risk
```

---

---

# ğŸ“ **Summary - Key Concepts to Memorize:**

## CELERY & REDIS:
1. **Serialization**: Python objects â†’ JSON â†’ UTF-8 bytes â†’ Redis
2. **Broker**: Redis Lists (LPUSH/RPOP), Hash Maps (task state)
3. **Worker**: BRPOP (blocking), not busy-wait; Prefetch = in-memory buffer
4. **Why not Threads**: File Descriptors run out at 1024 connections (before memory/GIL)

## MIP SOLVER:
1. **Branch and Bound**: Tree search with pruning; Upper Bound guide
2. **Linear Relaxation**: Relax binaryâ†’continuous to get fast UB; helps pruning
3. **No Overlap**: x[i,shift1,r] + x[i,shift2,r] â‰¤ 1
4. **Pruning Logic**: If (current_UB < best_found) â†’ Prune entire branch

## PYDANTIC & ORM:
1. **Parsing vs. Validation**: Parsing converts types; validation checks correctness
2. **Session & ACID**: add() marks pending; commit() executes SQL; Atomicity = all-or-nothing
3. **PostgreSQL**: Relational, Foreign Keys, ACID â†’ perfect for scheduling complexity

---
