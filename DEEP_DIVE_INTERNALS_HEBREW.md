---
# ğŸ”¬ Smart Scheduling System - Complete Technical Mastery Guide
## Advanced Deep-Dive Into Architecture, Code, and Implementation

**Target Audience:** Defense Panel of Expert CS Professors  
**Goal:** Demonstrate complete architectural understanding and code-level expertise

---

## Table of Contents
1. [Architecture & System Overview](#q4-complete-architecture-overview)
2. [Question 1: Database Flow & Pydantic/PostgreSQL](#q1-database-flow--pydanticpostgresql-design)
3. [Question 2: MIP Solver - Building Variants](#q2-mip-solver--building-and-providing-variants)
4. [Question 3: Celery/Redis/Flower Implementation](#q3-celery-redis-and-flower--complete-procedure)
5. [Question 4: Architecture Deep Dive](#q4-complete-architecture-overview)
6. [Question 5: Authentication (OAuth/JWT)](#q5-authentication-implementation)
7. [Question 6: Docker & Containerization](#q6-docker-rationale)
8. [Question 7: Critical Code Analysis](#q7-critical-code-and-bottlenecks)
9. [Question 8: Constraint Service Purpose](#q8-why-constraint-service-after-mip)
10. [Technical Summary & Key Concepts](#technical-summary--memorization-guide)

---

# **TOPIC 1: Celery & Redis - Mechanical Deep Dive**

## 1. SERIALIZATION - What Happens When Calling `task.delay(run_id=123)`?

### ğŸ” Step-by-Step Process:

```python
# Code in Frontend:
response = requests.post("/api/optimize", json={"weekly_schedule_id": 456})

# Code in Backend:
@app.post("/api/optimize")
async def optimize(data: OptimizeRequest):
    task = run_optimization_task.delay(run_id=456)  # â† Magic happens here!
    return {"task_id": task.id}
```

### ğŸ“¦ Serialization Process:

```
Step 1: Python Object
  run_id = 456  (int in memory)

Step 2: Serialization (Python â†’ JSON)
  Celery + Python-MIP by default uses JSON
  
  run_id=456 â†’
    JSON: "456"  (string in text format)
  
  If we had complex objects (numpy arrays, etc.):
    Celery would send pickle (binary format, unsecure!)
    or MessagePack (binary, more compact)

Step 3: Encoding to Bytes
  JSON string "456" â†’
    UTF-8 bytes: b'456'
    (Every character in JSON becomes bytes)

Step 4: Task Envelope Creation
  Celery builds a "task message":
  {
    "id": "abc-123-def",
    "task": "backend.app.tasks.run_optimization_task",
    "args": [456],  â† the arguments
    "kwargs": {},
    "exchange": "celery",
    "routing_key": "celery",
    "properties": {
      "correlation_id": "abc-123",
      "reply_to": "celery.reply.queue"
    },
    "headers": {
      "task_id": "abc-123-def",
      "lang": "py",
      "group": null
    }
  }

Step 5: Serialization of the Envelope
  All JSON â†’ bytes again
  
Step 6: To Redis!
```

### ğŸ’¾ ×‘Redis ×¢×›×©×™×•:

```
Redis List (×‘××§×•× Queue):
  Key: "celery"  (default queue name)
  Value: [
    <serialized message 1>,
    <serialized message 2>,
    ...
  ]

Redis actually stores it as:
  LPUSH celery <serialized_bytes>
```

---

## 2. THE BROKER (Redis) - ××‘× ×” × ×ª×•× ×™× ×¡×¤×¦×™×¤×™

### ğŸ”´ Redis Data Structures ×©Celery ××©×ª××©:

```
1ï¸âƒ£ LISTS (×¢×™×§×¨×™ - ×¢×‘×•×¨ Task Queue)
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   
   Key: "celery"  (Queue name)
   Type: List
   
   Redis command: LPUSH celery <task_payload>
   
   ××‘× ×”:
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ celery (List)                    â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚ [0] â†’ {"task": "run_opt...", ... â”‚  â† ×œ××—×•×§ ×¢× RPOP
   â”‚ [1] â†’ {"task": "run_opt...", ... â”‚
   â”‚ [2] â†’ {"task": "run_opt...", ... â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   
   Worker ×¢×•×©×” RPOP (Right Pop) ×‘×œ×•×œ××”
   (××§×‘×œ ××”×§×¦×” ×”×™×× ×™, ××˜×‘×¢×•×ª ××”×©×××œ)

2ï¸âƒ£ HASH MAPS (×¢×‘×•×¨ Task State)
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   
   Key: "celery-task-meta-<task_id>"
   Type: Hash
   
   Value:
   {
     "status": "PENDING",  â†’ ×©×œ××—×¨ ×–××Ÿ: "STARTED", "SUCCESS", "FAILURE"
     "result": null,       â†’ ××—×¨×™ ×‘×“×™×§×”: <actual result>
     "traceback": null,
     "children": [],
     "date_done": null
   }
   
   Frontend ×¢×•×©×” Polling ×›×“×™ ×œ×‘×“×•×§:
   GET celery-task-meta-abc-123-def â†’ {"status": "PENDING"}
   (××—×¨×™ 2 ×©× ×™×•×ª)
   GET celery-task-meta-abc-123-def â†’ {"status": "RUNNING"}
   (××—×¨×™ ×¢×•×“ 30 ×©× ×™×•×ª)
   GET celery-task-meta-abc-123-def â†’ {"status": "SUCCESS", "result": {...}}

3ï¸âƒ£ SETS (×¢×‘×•×¨ Task Acks ×•-Reservations - complex)
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   
   ×›×©Worker ×§×•×¨× task:
     - ××•×¡×™×£ ××ª task_id ×œSET ×©×œ "active tasks"
     - ×× Worker nope ×›××• 5 ×“×§×•×ª ×œ×œ× "heartbeat" â†’ removes automatically
```

### ğŸ“‹ Task Payload ×‘Redis - ××” ×–×” ×œ××¢×©×”?

```json
{
  "body": [
    "[456]",  // args: [run_id=456]
    {},       // kwargs: empty
    {
      "callbacks": null,
      "errbacks": null,
      "chain": null,
      "chord": null
    }
  ],
  "headers": {
    "lang": "py",
    "task": "backend.app.tasks.run_optimization_task",
    "id": "c4f53-8a92-4d21-9e8e-abc123def456",
    "shadow": null,
    "eta": null,
    "expires": null,
    "group": null,
    "retries": 0,
    "timelimit": [3600, 3300],  // Hard limit 1h, Soft 55m
    "parent_id": null,
    "root_id": "c4f53-8a92-..."
  },
  "content-encoding": "utf-8",
  "content-type": "application/json"
}
```

---

## 3. THE WORKER - ××™×š ×”×•× ×™×•×“×¢ ×©×™×© Task?

### ğŸ¤– Worker Loop - ×œ× Busy Wait!

```python
# Celery Worker ×‘×¤×•×¢×œ ×¢×©×” ××©×”×• ×›××•:

def worker_main_loop():
    while True:
        # âŒ ×–×” ×œ× busy wait! 
        # ××“×•×¢? ×›×™ ×–×” ×”×™×” ×‘×–×‘×•×– ××—×•×– CPU
        
        # âœ… ×–×” ××” ×©×××ª ×§×•×¨×”:
        
        # 1. Block on Redis (×ª×©×•××ª ×œ×‘!)
        #    Worker ×¢×•××“ ×‘×—×›×™×™×” ×¢×“ ×©×ª×’×™×¢ task (OS level blocking)
        task = redis.BRPOP("celery", timeout=1)
        #    â†‘ BRPOP = "Blocking Right Pop"
        #    Worker SLEEPS ×¢×“ ×©×™×© ××©×”×• ×‘×ª×•×¨
        
        if task:
            # 2. Mark as started
            update_task_state(task_id, "STARTED")
            
            # 3. Execute
            result = run_optimization_task(task.args[0])
            
            # 4. Mark as done
            update_task_state(task_id, "SUCCESS", result=result)
        else:
            # timeout hit, continue loop
            continue
```

### âš™ï¸ Prefetch Multiplier - ××” ×–×” ×‘×“×™×•×§?

```
×‘×¨×™×¨×ª ××—×“×œ: worker_prefetch_multiplier = 4
(×‘×¤×¨×•×™×§×˜ ×©×œ×š: 1, ×›×™ MaxTasksPerChild = 50)

××” ×–×” ×¢×©×”?

scenario: Queue ×™×© 10 tasks

Prefetch=4:
  Worker ×§×•×¨× 4 tasks ×-Redis ×‘×‘×ª ××—×ª
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Redis      â”‚
  â”‚ Queue [10] â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
  BRPOP x4
         â”‚
         â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Worker Memory      â”‚
  â”‚ [task1, task2,     â”‚
  â”‚  task3, task4] â†   â”‚ In-memory prefetch buffer
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  
  Worker ×¢×•×‘×“ ×¢×œ task1
  ×‘×• ×–×× ×™×ª, ×”×•× ×›×‘×¨ ×§×¨× ××ª 2,3,4 ××”×¨×—×•×‘
  
  Advantages:
    âœ… ×× task1 + task2 ×§×˜× ×™×, Worker ×œ× ×—×•×–×¨ ×œ-Redis
    âœ… × ×™×¦×•×œ ×‘× ×“×•×•×™×“×ª ××”×™×¨ ×™×•×ª×¨
  
  Disadvantages:
    âŒ ×× Worker × ×¤×œ ×¢× task3 ×‘××–×™×›×¨×•×Ÿ = ×”×•× lost (×œ× ×‘-Redis)
    âŒ Memory overhead ×× tasks ×’×“×•×œ×™×

×‘×¤×¨×•×™×§×˜ ×©×œ×š:
  prefetch_multiplier = 1
  â†’ Worker ×§×•×¨× ×¨×§ 1 task ×‘×‘×ª ××—×ª
  â†’ ×™×•×ª×¨ safe (××‘×œ ×§×¦×ª ×™×•×ª×¨ slow)
```

---

## 4. THE "WHY" - Python Thread vs. Celery - ××™×–×” ××©××‘ ×™×¡×ª×™×™× ×¨××©×•×Ÿ?

### ğŸ”¥ Load Test: 100 Users Ã— 300-second Solve

#### Scenario A: Simple Python Threads (âŒ ×’×¨×•×¢)

```python
# ×‘FastAPI ×‘×œ×™ Celery:
@app.post("/optimize")
async def optimize(data):
    # Just call directly!
    result = solver.solve()  # Blocks for 300 seconds
    return result
```

```
×”×‘×¢×™×”:
  - ×›×œ ×‘×§×©×” = × ×•×¦×¨×ª Thread ×‘JVM/OS
  - 100 ×‘×§×©×•×ª ×‘×•-×–×× ×™×ª = 100 threads ×—×¡×•××•×ª
  - ×›×œ thread = ~2MB stack memory (default)
  - Total: 100 * 2MB = 200MB ×¨×§ ×œstacks!
  
  ×× ×”××›×•× ×” ×™×© 4GB RAM:
    Memory limit reached â‰ˆ 2000 threads
    
    But:
    âŒ GIL (Global Interpreter Lock) ×‘Python!
    â†’ ××¤×™×œ×• ×¢× threads, ×¨×§ ××—×“ ×‘×¨×™×¥ ×‘×¤×•×¢×œ
    â†’ 99 threads ×—×•×›×™×
    â†’ Context switches = ×‘×–×‘×•×– CPU
    
    âŒ File Descriptors!
    â†’ ×›×œ connection HTTP = 1 file descriptor (FD)
    â†’ Linux default limit: 1024 FDs per process
    â†’ ××—×¨×™ 1024 connections: "Too many open files" âŒ
```

### ××” ×™×™×¡×ª×™×™× ×¨××©×•×Ÿ?

```
1ï¸âƒ£ File Descriptors (1024) â† ×–×” ×”×¨××©×•×Ÿ! âŒ

   ×›×œ HTTP connection ×¦×•×¨×š 1 FD
   Server crash ×‘-1000 ×‘×§×©×•×ª ×‘×•-×–×× ×™×ª
   
   Error: "OSError: [Errno 24] Too many open files"

2ï¸âƒ£ Memory (2GB for threads)
   100 threads * 2MB = 200MB - ×‘×¡×“×¨
   1000 threads * 2MB = 2GB - OOM Killer kills process
   
3ï¸âƒ£ GIL (Global Lock)
   ×œ× ×‘×“×™×•×§ "runs out" ××‘×œ context switches
   ××•×¨×™×“ throughput ××©××¢×•×ª×™×ª
```

#### Scenario B: Celery + Redis (âœ… ×˜×•×‘)

```
100 ×‘×§×©×•×ª:
  - FastAPI handler: 100ms ×›×œ ××—×ª (non-blocking!)
  - Tasks ×‘-Redis: ××”×“×•×¨×•×ª ×œ×§×• ××—×™×¦×”
  - 4 Celery Workers: ×—×œ×•×§×ª ×”×¢×‘×•×“×”
  
  Memory:
    - FastAPI: ~100MB (constant)
    - 4 Worker processes: 4 * 300MB = 1.2GB
    - Redis: ~100MB
    Total: ~1.4GB (predictable!)
  
  File Descriptors:
    - FastAPI: ~20-50 FDs
    - Redis: ~10 FDs
    - Workers: ~5 FDs each * 4 = 20 FDs
    Total: ~100 FDs (××ª×—×ª ×œ×’×‘×•×œ ×©×œ 1024)
  
  GIL:
    - âŒ ×›×œ Worker ×ª×”×œ×™×š ××©×œ×• (separate Python interpreter)
    - âœ… ××™×Ÿ GIL ×‘×™×Ÿ processes (×¨×§ ×‘×ª×•×š)
    - âœ… True parallelism!
```

---

---

# **TOPIC 2: MIP Solver Black Box - Branch and Bound**

## 1. The Search Tree - Branch and Bound (B&B)

### ğŸ“Š ×”××¨××” ×”×›×œ×œ×™:

```
×‘×¢×™×”: ×”×§×¦×” 50 ×¢×•×‘×“×™× Ã— 100 ××©××¨×•×ª Ã— 5 ×ª×¤×§×™×“×™×

×× × ×©×ª××© ×‘Brute Force:
  - ××¡×¤×¨ ××©×ª× ×™×: 50 * 100 * 5 = 25,000 ×‘×™× ××¨×™×
  - Combinations: 2^25000 (×›×œ×•××¨... ×ª×•×š 10^7000 ×©× ×™×•×ª)
  - âŒ ×‘×œ×ª×™ ××¤×©×¨×™

×¤×ª×¨×•×Ÿ: Branch and Bound!
  - ×¡×“×¨ ×—×™×¤×•×© ×—×›×
  - ×’×™×–×•× (Pruning) ×©×œ ×¢× ×¤×™× ×—×¡×¨×™ ×ª×§×•×•×”
```

### ğŸŒ³ ×“×•×’××” ×§×˜× ×” - 3 ××©×ª× ×™× ×‘×™× ××¨×™×™×

```
××˜×¨×”: Maximize: 2*x1 + 3*x2 + x3 (×›××©×¨ x1,x2,x3 âˆˆ {0,1})

×©×œ×‘ 1: Linear Relaxation (treat as continuous)
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  x1, x2, x3 âˆˆ [0, 1] (continuous)
  
  Solution: x1=1, x2=1, x3=1 â†’ Objective = 2 + 3 + 1 = 6
  (×× ×”×™×• ×§×™×™××™× ××™×œ×•×¦×™× × ×•×¡×¤×™×, ×”×™×™× ×• ×§×¦×ª ×¤×—×•×ª ×-6)

  ×–×” **Upper Bound** = 6
  â†’ ×× ×—× ×• ×™×•×“×¢×™× ×©×”×¤×ª×¨×•×Ÿ ×”×©×œ× ×œ×¢×•×œ× ×œ× ×™×¢×œ×” ×¢×œ 6

×©×œ×‘ 2: Branch on x1
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  
           [Root: UB=6]
           /         \
        /               \
  [x1=0]              [x1=1]
  UB=4.5              UB=5.8
    /                   /
   /                    \
Branch on x2          Branch on x2
(x1=0)                (x1=1)
     
×©×œ×‘ 3: Solve each subproblem
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  
  Subproblem: x1=0, x2=1, x3âˆˆ[0,1]
    Objective â‰¤ 0 + 3 + 1 = 4 (Upper Bound)
    â†’ ×× ×× ×—× ×• ×›×‘×¨ ××¦×× ×• ×¤×ª×¨×•×Ÿ ×¢× 4, prune!
    
  Subproblem: x1=1, x2=1, x3=0
    Objective = 2 + 3 + 0 = 5 (Integer feasible!)
    â†’ ×–×” ×¤×ª×¨×•×Ÿ ×—×•×§×™, update best found = 5

×©×œ×‘ 4: Pruning
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  
  ×× ×©× ×™ × ×•×›×œ:
    - ××¦×× ×• ×‘×¨ = 5
    - Branch ×‘×Ÿ ×™×© Upper Bound = 4.5
    
  â†’ PRUNE! ×œ×¢×•×œ× ×œ× ×ª×•×›×œ ×œ×”×™×•×ª ×˜×•×‘ ×-5
```

### ğŸ”ª Pruning Rules (×™×¡×•×“ ×”××”×™×¨×•×ª!)

```
×›×œ×œ 1: Bound Pruning
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  ×× Upper Bound ×©×œ Branch < Best Found So Far
  â†’ Prune (×œ×¢×•×œ× ×œ× ×ª×•×›×œ ×œ×”×™×•×ª ×”×”×¦×¢×” ×”×˜×•×‘×” ×‘×™×•×ª×¨)

×›×œ×œ 2: Infeasibility Pruning
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  ×× ×”sub-problem ×”×•× INFEASIBLE
  â†’ Prune (××™×Ÿ ×¤×ª×¨×•×Ÿ ×›××Ÿ)

×›×œ×œ 3: Integrality Pruning
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  ×× ×›×œ ×”××©×ª× ×™× ×‘×¤×ª×¨×•×Ÿ ×”× ×›×‘×¨ 0 ××• 1
  â†’ ×™×© ×œ× ×• ×¤×ª×¨×•×Ÿ ×©×œ×! Save it, don't branch further
```

---

## 2. Linear Relaxation - ×œ××” ×–×” ×˜×¨×™×§ ×××™×ª×™?

### ğŸ”“ ××” ×§×•×¨×” ×›×©××ª×¢×œ××™× ××”××’×‘×œ×” ×©×œ "×‘×™× ××¨×™"?

```
×‘×¢×™×” ××§×•×¨×™×ª:
  max: 2*x1 + 3*x2 + x3
  s.t.
    x1 + x2 <= 1.5  (constraint)
    x1, x2, x3 âˆˆ {0, 1}  (binary!)

Linear Relaxation:
  max: 2*x1 + 3*x2 + x3
  s.t.
    x1 + x2 <= 1.5
    x1, x2, x3 âˆˆ [0, 1]  (continuous!)
    
  Relaxed Solution:
    x1 = 0.5, x2 = 1, x3 = 1
    Objective = 2*0.5 + 3*1 + 1 = 5.5
    
  ×–×” Upper Bound!
  â†’ ×¤×ª×¨×•×Ÿ ×©×œ× ×œ×¢×•×œ× ×œ× ×™×¢×œ×” ×¢×œ 5.5
```

### ğŸ¯ ×œ××” ×–×” ××”×™×¨?

```
1. Linear Programs ×”× ×§×œ×™× ×œ×¤×ª×•×¨!
   â†’ Simplex Algorithm ×™×›×•×œ ×œ×¤×ª×•×¨ ×‘×©× ×™×•×ª
   â†’ ××¤×™×œ×• ×¢× 1 ××™×œ×™×•×Ÿ ××©×ª× ×™×!

2. Upper Bound ××™×“ ××•×¢×™×œ!
   - ×¢× Upper Bound = 5.5
   - ×× ×× ×—× ×• ××¦×× ×• ×¤×ª×¨×•×Ÿ ×‘×Ÿ 5
   - ×× ×—× ×• ×™×•×“×¢×™×: optimal âˆˆ [5, 5.5]
   - ×”×¤×¢×¨ ×”×•× ×§×˜×Ÿ!
   
   ×× ×¢×“×™×™×Ÿ ×œ× ××¦×× ×• ×¤×ª×¨×•×Ÿ:
   - × ×™×ª×Ÿ ×œ×”××©×™×š ×œ×‘×“×•×§ ×¨×§ branches ×¢× potential

3. Pruning ×˜×•×‘ ×™×•×ª×¨!
   - ×™×•×ª×¨ branches ××•×¤×©×œ×•×ª
   - ×”×—×™×¤×•×© ×¢×¥ ×”×•× ×§×˜×Ÿ ×™×•×ª×¨
```

---

## 3. Mathematical Equation - No Overlap Constraint

### ğŸ“ ×¢×‘×•×¨ ××©××¨×•×ª ×—×•×¤×¤×•×ª, ××©×ª× ×” ×™×—×™×“

```
×ª×¨×’×•× ×Python ×œ-Math:

# Python:
for emp in employees:
    for shift1, shift2 in overlapping_pairs:
        for role in roles:
            if (emp, shift1, role) in x and (emp, shift2, role) in x:
                model += x[(emp, shift1, role)] + x[(emp, shift2, role)] <= 1

# Math (×¢×‘×•×¨ ×¢×•×‘×“ specific i, ×ª×¤×§×™×“ specific r):

âˆ‘_{sâˆˆS_overlapping(shift1)} x_{i,s,r} + x_{i,shift1,r} â‰¤ 1

××• ×‘×“×¨×š ×™×•×ª×¨ ×¤×©×•×˜×” ×œ×©×ª×™ ××©××¨×•×ª ×—×•×¤×¤×•×ª:

x_{i, shift1, r} + x_{i, shift2, r} â‰¤ 1

×›××©×¨:
  i = employee index
  shift1, shift2 = overlapping shift indices
  r = role id
  x_{i,j,r} âˆˆ {0, 1} = binary variable
```

### ×× ×™×© N overlapping shifts:

```
×¢×‘×•×¨ ×¢×•×‘×“ ×•××©××¨×•×ª ××¨×•×‘×•×ª ×©×—×•×¤×¤×•×ª ×‘×—×œ×§×Ÿ:

âˆ‘_{j âˆˆ shifts_that_overlap_with_shift1} x_{i,j,r} â‰¤ 1

×–×” ××•×•×“×: ×¢×•×‘×“ ×™×›×•×œ ×œ×”×™×•×ª ×‘×œ×›×œ ×”×™×•×ª×¨ 1 ××”××©××¨×•×ª ×”×—×•×¤×¤×•×ª
```

---

## 4. Pruning Logic - Score 100 vs. UB 80

### ğŸ¯ ×”-Moment of Truth:

```
Scenario:
  - Best solution found so far: Score = 100
  - Current branch being explored:
    * Relaxation gives UB = 80
    * (×›×œ×•××¨, ××¤×™×œ×• ×‘×¢×•×œ× ××•×©×œ×, 80 ×”×•× ×”××§×¡×™××•×)

Logic:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ if (current_branch_UB < best):  â”‚
  â”‚   PRUNE this entire branch!     â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  
  ×›××Ÿ:
    UB = 80
    best = 100
    80 < 100? YES!
    
    â†’ PRUNE!
    
  ××“×•×¢?
    - ×–×” impossible ×©× ××¦× ××©×”×• ×˜×•×‘ ×™×•×ª×¨ ×-100 ×‘×‘ranch ×–×”
    - ×›×œ ×”×™×œ×“×™× ×©×œ branch ×–×” ×™×”×™×• ×‘×˜×— ×¢× score â‰¤ 80
    - ×›×œ ×¢×‘×•×“×” × ×•×¡×¤×ª ×›××Ÿ ×”×™× ×‘×–×‘×•×–
```

### ğŸ“Š ×“×•×’××” ×¢× ×¡×¤×™×¨×”:

```
×‘×œ×™ Pruning:
  2^n ××¤×©×¨×•×™×•×ª = 2^25000 (×œ×“×•×’××”)
  Time: âˆ ×©× ×™×•×ª

×¢× Pruning (×ª×§×¦×™×¨):
  Start: 100 branches
  â†“ (×œ××—×¨ Linear Relaxation ×©×œ ×›×œ ××—×“)
  â†“ Prune 70 branches (UB < best)
  â†“ Explore 30 branches further
  â†“ Branch further: 30 * 2 = 60
  â†“ Prune 50: 10 remain
  â†“ ... iterate until convergence
  
  Final explored: ~150-200 nodes (×× ×”parameters ×˜×•×‘×™×)
  
  Time: ×©× ×™×•×ª ×¢×“ ×“×§×•×ª (×‘×¢×§×•× ×©×‘×—×¨× ×•)!
```

---

---

# **TOPIC 3: Application Stack - Pydantic, ORM, Database**

## 1. Pydantic vs. Dict - ×œ××” Schemas?

### ğŸ†š ×”×©×•×•××”:

```python
# âŒ ×œ×œ× Pydantic (Just Dicts):
@app.post("/optimize")
def optimize(data: dict):
    run_id = data["weekly_schedule_id"]
    # ×‘×¢×™×•×ª:
    # - run_id could be "not a number" â†’ string!
    # - data could be {"random_field": 123}
    # - No type checking
    # - No IDE autocomplete

# âœ… ×¢× Pydantic:
from pydantic import BaseModel

class OptimizeRequest(BaseModel):
    weekly_schedule_id: int

@app.post("/optimize")
def optimize(data: OptimizeRequest):
    run_id = data.weekly_schedule_id  # âœ… guaranteed int!
```

### ğŸ“‹ Data Parsing vs. Validation:

```
PARSING (×××™×¨ ×¡×•×’×™×):
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  
  JSON Input:
    {"weekly_schedule_id": "456"}  â† string!
  
  Pydantic Parsing:
    "456" (string) â†’ 456 (int)
    
  Explicit Coercion Rules:
    "456" â†’ int("456") â†’ 456 âœ…
    "abc" â†’ int("abc") â†’ ValueError âŒ
    456 (already int) â†’ 456 âœ…

VALIDATION (×‘×•×“×§ × ×›×•× ×•×ª):
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  
  After parsing (data is already correct type):
    weekly_schedule_id = 456 (int)
  
  Validators can check:
    - Is 456 a valid weekly_schedule_id? (exists in DB?)
    - Is 456 > 0? (positive?)
    - Is 456 < 1000000? (reasonable range?)
    
  Example:
    class OptimizeRequest(BaseModel):
        weekly_schedule_id: int
        
        @field_validator('weekly_schedule_id')
        def validate_schedule(cls, v):
            if v < 1:
                raise ValueError('Must be positive')
            return v
```

### ğŸ”¥ Runtime Behavior - String to Int:

```python
# Frontend sends:
json_data = {"weekly_schedule_id": "456"}

# Backend FastAPI:
request = OptimizeRequest(**json_data)

# Step-by-step in Pydantic:
1. Parse JSON string "456" â†’ Python object {"weekly_schedule_id": "456"}
2. Check schema: weekly_schedule_id is int, got str
3. Try coerce: int("456") â†’ 456
4. Success! request.weekly_schedule_id = 456 (now int)

# If it was invalid:
json_data = {"weekly_schedule_id": "not_a_number"}

1. Parse JSON â†’ {"weekly_schedule_id": "not_a_number"}
2. Check schema: int expected, got str
3. Try coerce: int("not_a_number") â†’ ValueError
4. Pydantic catches: raises ValidationError
5. FastAPI returns: HTTP 422 Unprocessable Entity
   {
     "detail": [
       {
         "type": "value_error",
         "loc": ["body", "weekly_schedule_id"],
         "msg": "value is not a valid integer"
       }
     ]
   }
```

---

## 2. SQLAlchemy - Session & Transaction (ACID)

### ğŸ”„ ××” ×§×•×¨×” ×¢× `db.add(model)`?

```python
# Code:
session = SessionLocal()
run = SchedulingRunModel(
    weekly_schedule_id=456,
    status="PENDING"
)
session.add(run)  # â† What happens?
session.commit()
```

### Step-by-step:

```
×©×œ×‘ 1: session.add(run)
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  
  âœ… Add to session's identity map
  â””â”€ session._identity_map[id(run)] = run
  
  âœ… Mark as "pending" (not yet in DB)
  â””â”€ run._sa_instance_state.persistent = False
  
  âŒ NOT in database yet!
  â””â”€ No SQL executed!
  
  ×–×” ×—×™×–×•×™ ×‘×œ×‘×“ ×©×œ memory

×©×œ×‘ 2: session.commit()
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  
  âœ… Session flush (×™×™×¦×•× ×œDB)
    INSERT INTO scheduling_run (weekly_schedule_id, status)
    VALUES (456, 'PENDING')
    RETURNING id;
  
  âœ… Commit transaction
    COMMIT;
  
  âœ… Mark as persistent
    run._sa_instance_state.persistent = True
    run.id = <generated_id>
  
  × ×ª×•× ×™× ×‘DB!
```

### ğŸ“Š Transaction & ACID:

```
ACID = Atomicity, Consistency, Isolation, Durability

×‘×”×§×©×¨ ×©×œ× ×• (scheduling):

ATOMICITY:
  â”€â”€â”€â”€â”€â”€
  
  ×›××©×¨ ×× ×—× ×• ×™×•×¦×¨×™× SchedulingRun ×•×›×œ SchedulingSolutions:
  
  transaction = [
    INSERT INTO scheduling_run (status) VALUES ('PENDING'),
    INSERT INTO scheduling_solution (run_id, user_id, ...) VALUES (...),
    INSERT INTO scheduling_solution (run_id, user_id, ...) VALUES (...),
    ... 1000 more inserts ...
  ]
  
  commit();
  
  ×× ×”×§×•×‘×¥ ×•×”-1001 insert × ×›×©×œ:
    â†’ Entire transaction rolled back
    â†’ 0 ×©×•×¨×•×ª ×‘DB
    â†’ No orphan records
    
  ××“×•×¢ ×–×” critical ×œScheduling?
    - SchedulingRun ×œ×œ× Solutions = ×—×¡×¨ ××˜×¨×”
    - Solutions ×œ×œ× Run = orphaned data
    - Atomicity = ××• ×›×œ ××• ×›×œ×•×!

CONSISTENCY:
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  
  Foreign keys enforced:
    INSERT INTO scheduling_solution (run_id, user_id, ...)
    VALUES (999, 888, ...)
    
  ×× run_id=999 ×œ× ×§×™×™× â†’ ERROR! (FK violation)
  
  Constraints enforced:
    MAX_HOURS_PER_WEEK must be valid
    UNIQUE constraints honored

ISOLATION:
  â”€â”€â”€â”€â”€â”€â”€
  
  ×× 2 users ×œ×•×§×—×•×ª optimization ×‘×•-×–×× ×™×ª:
  
  User A: SELECT weekly_schedule_id=1
  User B: SELECT weekly_schedule_id=1
  
  ×¢× ACID isolation:
    - User A ×‘×˜×•×— ×©B ×œ× ×™×¢×“×›×Ÿ ××ª ×–×” ×‘×¢××¦×¢
    - ×›×œ Transaction ×‘×‘×“×“×• (even if concurrent)

DURABILITY:
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  
  ××—×¨×™ COMMIT:
    - × ×ª×•× ×™× ×›×ª×•×‘×™× ×œ×“×™×¡×§
    - ××¤×™×œ×• ×× server crashing, data survives
    - Recovery ×Power Loss ××•×‘×˜×—
```

---

## 3. PostgreSQL vs. NoSQL (Mongo) - ×œ××” Relational?

### ğŸ†š ×”×”×©×•×•××”:

```
SCHEDULING REQUIREMENTS:

1. Complex Relations
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   
   User â† has many â†’ Role
   User â† works â†’ Shift
   Shift â† requires â†’ Role
   User â† has-preferences â†’ Shift
   
   SQL (Joins):
     SELECT u.name, s.date, r.name
     FROM users u
     JOIN scheduling_solution ss ON u.id = ss.user_id
     JOIN planned_shift s ON ss.planned_shift_id = s.id
     JOIN role r ON ss.role_id = r.id
     WHERE s.weekly_schedule_id = 456;
   
   (Clean, Declarative)
   
   MongoDB (Embedded/References):
     db.users.find({...}).aggregate([
       {$lookup: {from: "scheduled", ...}},
       {$lookup: {from: "shifts", ...}},
       ...
     ])
   
   (Complex, verbose)

2. Data Integrity (FOREIGN KEYS)
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   
   SQL:
     ALTER TABLE scheduling_solution
     ADD CONSTRAINT fk_user
     FOREIGN KEY (user_id)
     REFERENCES users(id)
     ON DELETE RESTRICT;
   
   â†’ Database enforces:
     Can't delete user if they have assignments!
   
   MongoDB:
     No enforced FKs!
     â†’ Data corruption possible:
       {user_id: 999} but user 999 doesn't exist
   
   â†’ Application must handle (error-prone)

3. ACID Transactions
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   
   SQL (Multi-row):
     BEGIN;
     INSERT INTO scheduling_run ...
     INSERT INTO scheduling_solution ... (1000 rows)
     COMMIT;
   
   â†’ All or nothing guarantee
   
   MongoDB:
     Single-document ACID (limited)
     Multi-document ACID (added in 4.0+, less mature)
   
   â†’ Risk of partial failures

4. Querying Flexibility
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   
   Questions we ask:
     - Find all employees assigned to shift X
     - Find all shifts a user is assigned to
     - Find overlaps
     - Aggregate hours per employee
   
   SQL:
     SELECT * FROM scheduling_solution
     WHERE planned_shift_id = 456;
     
     (1 query, very fast)
   
   MongoDB:
     db.scheduling_solution.find({
       planned_shift_id: ObjectId("...")
     })
     
     (OK, but embedded docs make it harder)

CONCLUSION:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

âœ… PostgreSQL ×“×•×‘×¨×ª:
  - Complex relationships (many JOINs)
  - Strong consistency (ACID)
  - Referential integrity
  - This is relational data!

âŒ MongoDB ×¢×“×™×£:
  - Flexible schema (but ours is fixed!)
  - Horizontal scaling (we don't need, single DB)
  - Document querying (document structure not ideal for scheduling)
```

### ğŸ“Š Schema Comparison:

```
POSTGRES (Relational - Normalized):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

TABLE users:
  id INT PRIMARY KEY
  name VARCHAR
  roles INT[] (array of role IDs)

TABLE scheduling_solution:
  id INT PRIMARY KEY
  run_id INT FOREIGN KEY â†’ scheduling_run
  user_id INT FOREIGN KEY â†’ users
  shift_id INT FOREIGN KEY â†’ planned_shift
  role_id INT FOREIGN KEY â†’ roles

Queries are clean:
  SELECT COUNT(*) FROM scheduling_solution
  WHERE user_id = 123 AND role_id = 1;

MONGODB (Document - Denormalized):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Document structure:
  db.scheduling_solutions.insertOne({
    _id: ObjectId(...),
    run: {
      id: 1,
      status: "PENDING",
      started_at: Date(...),
      config: { weight_fairness: 0.5, ... }
    },
    user: {
      id: 123,
      name: "John",
      roles: [1, 2, 3]
    },
    shift: {
      id: 456,
      date: Date(...),
      start: Time(...),
      end: Time(...)
    },
    role: {
      id: 1,
      name: "Waiter"
    }
  })

Queries are verbose:
  db.scheduling_solutions.find({
    "user.id": 123,
    "role.id": 1
  }).count()

Problems:
  - If user 123 is updated, every document with that user needs update
  - Data duplication + consistency risk
```

---

---

# ğŸ“ **Summary - Key Concepts to Memorize:**

## CELERY & REDIS:
1. **Serialization**: Python objects â†’ JSON â†’ UTF-8 bytes â†’ Redis
2. **Broker**: Redis Lists (LPUSH/RPOP), Hash Maps (task state)
3. **Worker**: BRPOP (blocking), not busy-wait; Prefetch = in-memory buffer
4. **Why not Threads**: File Descriptors run out at 1024 connections (before memory/GIL)

## MIP SOLVER:
1. **Branch and Bound**: Tree search with pruning; Upper Bound guide
2. **Linear Relaxation**: Relax binaryâ†’continuous to get fast UB; helps pruning
3. **No Overlap**: x[i,shift1,r] + x[i,shift2,r] â‰¤ 1
4. **Pruning Logic**: If (current_UB < best_found) â†’ Prune entire branch

## PYDANTIC & ORM:
1. **Parsing vs. Validation**: Parsing converts types; validation checks correctness
2. **Session & ACID**: add() marks pending; commit() executes SQL; Atomicity = all-or-nothing
3. **PostgreSQL**: Relational, Foreign Keys, ACID â†’ perfect for scheduling complexity

---

---

# **PART 2: MIP SOLVER INTERNALS**
## The Mathematics and Algorithm of Optimization

---

## 1. THE SOLVER INPUTS: What Data Structure Does MIP Need?

### ğŸ“¥ Data Flow into the Solver

Before the solver can work, we must provide it with structured input. The solver doesn't accept raw database objectsâ€”it needs **indices, matrices, and parameters**.

```python
# From: backend/app/services/optimization_data_services/optimization_data.py

class OptimizationData:
    """
    Data class to hold all extracted optimization data.
    This is the INPUT to the MIP solver.
    """
    
    def __init__(self):
        # SETS (Indices)
        self.employees: List[Dict] = []  # List of N employees
        self.shifts: List[Dict] = []     # List of M shifts
        self.roles: List[Dict] = []      # List of R role types
        
        # PARAMETERS (Numerical Data)
        self.availability_matrix: np.ndarray = None      # NÃ—M matrix: 1 if employee i can work shift j
        self.preference_scores: np.ndarray = None        # NÃ—M matrix: preference score 0.0-1.0
        
        # MAPPINGS (For efficient indexing)
        self.employee_index: Dict[int, int] = {}    # user_id -> array index i
        self.shift_index: Dict[int, int] = {}       # shift_id -> array index j
        
        # RELATIONSHIPS
        self.role_requirements: Dict[int, List[int]] = {}  # shift_id -> list of role_ids needed
        self.employee_roles: Dict[int, List[int]] = {}     # user_id -> list of role_ids qualified
        self.shift_overlaps: Dict[int, List[int]] = {}     # shift_id -> list of overlapping shift_ids
        
        # CONSTRAINTS (System Rules)
        self.system_constraints: Dict[SystemConstraintType, Tuple[float, bool]] = {}
        # e.g., {
        #   SystemConstraintType.MAX_HOURS_PER_WEEK: (40.0, True),
        #   SystemConstraintType.MAX_SHIFTS_PER_WEEK: (5, True),
        #   SystemConstraintType.MIN_REST_HOURS: (11, True)
        # }
```

### ğŸ” What the Solver Actually Receives

The solver receives `(data, config)` where:

```python
# From: backend/app/services/scheduling/mip_solver.py

def solve(self, data: OptimizationData, config: OptimizationConfigModel) -> SchedulingSolution:
    """
    Args:
        data: OptimizationData containing:
            - Indices: n_employees = 50, n_shifts = 100, roles = 5
            - Parameters: availability_matrix (50Ã—100), preference_scores (50Ã—100)
            - Sets: role_requirements, employee_roles, shift_overlaps
            - Constraints: system_constraints (from DB)
        
        config: Solver configuration:
            - max_runtime_seconds = 300
            - mip_gap = 0.05 (5% optimality gap)
            - weight_preferences = 0.4
            - weight_fairness = 0.3
            - weight_coverage = 0.3
    """
    
    n_employees = len(data.employees)
    n_shifts = len(data.shifts)
    
    # Validate matrix dimensions match
    assert data.availability_matrix.shape == (n_employees, n_shifts)
    assert data.preference_scores.shape == (n_employees, n_shifts)
```

### ğŸ“Š Example Input Data

For a small scheduling problem:

```
SETS (Indices):
  Employees: i âˆˆ {0, 1, 2, ..., 49}     (50 employees)
  Shifts:    j âˆˆ {0, 1, 2, ..., 99}     (100 shifts in the week)
  Roles:     r âˆˆ {1, 2, 3, 4, 5}        (Waiter, Chef, Manager, etc.)

PARAMETERS (Matrices):
  
  Availability Matrix A[i,j] âˆˆ {0, 1}:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”
    â”‚ Emp \ Shâ”‚  0   â”‚  1   â”‚  2   â”‚ ... â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¤
    â”‚    0    â”‚  1   â”‚  0   â”‚  1   â”‚ ... â”‚  (1 = available, 0 = not available)
    â”‚    1    â”‚  1   â”‚  1   â”‚  0   â”‚ ... â”‚
    â”‚    2    â”‚  0   â”‚  1   â”‚  1   â”‚ ... â”‚
    â”‚   ...   â”‚ ...  â”‚ ...  â”‚ ...  â”‚ ... â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜
  
  Preference Matrix P[i,j] âˆˆ [0.0, 1.0]:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”
    â”‚ Emp \ Shâ”‚   0   â”‚   1   â”‚   2   â”‚ ... â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¤
    â”‚    0    â”‚ 0.9   â”‚ 0.3   â”‚ 0.8   â”‚ ... â”‚  (1.0 = strongly prefer, 0.0 = hate)
    â”‚    1    â”‚ 0.7   â”‚ 0.9   â”‚ 0.2   â”‚ ... â”‚
    â”‚    2    â”‚ 0.1   â”‚ 0.8   â”‚ 0.6   â”‚ ... â”‚
    â”‚   ...   â”‚ ...   â”‚ ...   â”‚ ...   â”‚ ... â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜

CONSTRAINTS (System Rules):
  MAX_HOURS_PER_WEEK = 40 hours (HARD)
  MAX_SHIFTS_PER_WEEK = 5 shifts (HARD)
  MIN_REST_HOURS = 11 hours (HARD)

COVERAGE REQUIREMENTS:
  Shift 0: needs 2Ã— Waiter (role 1), 1Ã— Chef (role 2)
  Shift 1: needs 1Ã— Waiter (role 1), 1Ã— Manager (role 4)
  ...
```

---

## 2. DECISION VARIABLES: The Code Behind `_build_decision_variables()`

### ğŸ¯ The Critical Concept: Pruning at Variable Creation

The most important optimization happens **BEFORE solving**. We don't create a variable for every possible (employee, shift, role) combination. We **prune aggressively** by only creating variables for **feasible assignments**.

### ğŸ“ Mathematical Definition

For every combination of (i, j, r) where:
- i = employee index
- j = shift index  
- r = role id

We create a binary variable:

$$x_{i,j,r} \in \{0, 1\}$$

**Interpretation:**
- $x_{i,j,r} = 1$ if employee $i$ is assigned to shift $j$ in role $r$
- $x_{i,j,r} = 0$ otherwise

### ğŸ’£ Pruning: Why We Don't Create All Variables

**Without Pruning** (Exponential):
```
50 employees Ã— 100 shifts Ã— 5 roles = 25,000 potential variables
In unrestricted form: 2^25000 possible combinations

Even with the best solver: INFEASIBLE TO SOLVE
```

**With Pruning** (Manageable):
```
Apply filters BEFORE creating variables:
  Filter 1: availability_matrix[i,j] == 1
    â†’ Remove assignments where employee can't work shift
  Filter 2: role_id in employee_roles[i]
    â†’ Remove assignments where employee unqualified for role
  Filter 3: role_id in shift.required_roles
    â†’ Remove roles not needed for this shift

Result: Create only ~3,000-5,000 actual variables
Solver can optimize in seconds!
```

### ğŸ”´ The Exact Code: `_build_decision_variables()`

```python
# From: backend/app/services/scheduling/mip_solver.py

def _build_decision_variables(
    self,
    model: mip.Model,
    data: OptimizationData,
    n_employees: int,
    n_shifts: int
) -> Tuple[Dict, Dict]:
    """
    Build decision variables x[i,j,r] with AGGRESSIVE PRUNING.
    
    This is the core performance optimization:
    We only create variables for FEASIBLE (employee, shift, role) combinations.
    """
    x = {}  # Dictionary to store x[i,j,r] variables
    vars_by_emp_shift = {}  # Index for fast lookup
    
    # LOOP 1: For each employee
    for i, emp in enumerate(data.employees):
        
        # LOOP 2: For each shift
        for j, shift in enumerate(data.shifts):
            
            # ===== PRUNING FILTER 1: Availability =====
            # Only create variables if employee is AVAILABLE for this shift
            if data.availability_matrix[i, j] != 1:
                # Employee not available â†’ skip this (employee, shift) pair entirely
                # This eliminates ~50% of potential variables!
                continue
            
            # Get the required roles for this shift
            required_roles = shift.get('required_roles') or []
            
            # ===== PRUNING FILTER 2: Role Requirements =====
            # Only create variables if shift requires at least one role
            if not required_roles:
                # No roles needed for this shift â†’ skip
                continue
            
            # Get employee's qualified roles
            emp_role_ids = set(emp.get('roles') or [])
            
            # LOOP 3: For each role required by this shift
            for role_req in required_roles:
                role_id = role_req['role_id']
                
                # ===== PRUNING FILTER 3: Role Qualification =====
                # Only create variable if employee is QUALIFIED for this role
                if role_id in emp_role_ids:
                    # Create binary variable for this assignment
                    var = model.add_var(
                        var_type=mip.BINARY,
                        name=f'x_{i}_{j}_{role_id}'
                    )
                    
                    # Store in main dictionary: x[i, j, role_id] = var
                    x[i, j, role_id] = var
                    
                    # Build efficient index for constraint generation
                    if (i, j) not in vars_by_emp_shift:
                        vars_by_emp_shift[(i, j)] = []
                    vars_by_emp_shift[(i, j)].append(var)
                # else: Employee not qualified â†’ don't create variable
    
    return x, vars_by_emp_shift
```

### ğŸ“Š The Impact: Complexity Reduction

```
WITHOUT PRUNING:
  Potential variables: 50 Ã— 100 Ã— 5 = 25,000
  Solver complexity: O(2^25000)
  Solver time: IMPOSSIBLE

WITH PRUNING:
  After availability check: 50 Ã— 100 Ã— 0.5 Ã— 5 = 12,500  (50% reduction)
  After role requirement check: 12,500 Ã— 0.4 = 5,000     (40% reduction)
  After role qualification check: 5,000 Ã— 0.8 = 4,000    (80% reduction)
  
  Actual variables created: ~4,000
  Solver complexity: O(2^4000) with branch-and-bound pruning
  â†’ Practical time: 30-120 seconds
```

### ğŸ² Why Pruning Works: Example

```
Employee 0:
  - Roles qualified: {1 (Waiter), 2 (Chef)}
  - Available shifts: {0, 2, 5, 7, ...}

Shift 0:
  - Required roles: {1 (Waiter): 2 needed, 4 (Manager): 1 needed}

WITHOUT PRUNING, variables created:
  x[0, 0, 1] âœ… (qualified for role 1, shift requires 1, available)
  x[0, 0, 2] âŒ (unqualified - only has roles 1,2 but role 2 not needed)
  x[0, 0, 3] âŒ (unqualified)
  x[0, 0, 4] âŒ (unqualified - doesn't have role 4)
  x[0, 0, 5] âŒ (unqualified)
  ...

WITH PRUNING, variables created:
  x[0, 0, 1] âœ… (ONLY THIS ONE)
  
Result: 80% fewer variables for this shift!
Multiply across all shifts â†’ dramatic speedup
```

---

## 3. MATHEMATICAL FORMULATION: Decision Variables in Algebra

### ğŸ“ The Complete MIP Formulation

#### Decision Variables

$$x_{i,j,r} \in \{0, 1\} \quad \forall i \in I, j \in J, r \in R$$

Where:
- $I$ = set of employees (indices $i \in \{0, 1, ..., n-1\}$)
- $J$ = set of shifts (indices $j \in \{0, 1, ..., m-1\}$)
- $R$ = set of roles (indices $r \in \{1, 2, 3, 4, 5\}$)
- $x_{i,j,r}$ = 1 if employee $i$ assigned to shift $j$ in role $r$, else 0

#### Parameters

$$A_{i,j} \in \{0, 1\} \quad \text{Availability: 1 if employee } i \text{ available for shift } j$$

$$P_{i,j} \in [0, 1] \quad \text{Preference: employee } i \text{'s preference for shift } j$$

$$d_j \in \mathbb{R}^+ \quad \text{Duration: length of shift } j \text{ in hours}$$

$$c_{i,r} \in \{0, 1\} \quad \text{Capability: 1 if employee } i \text{ qualified for role } r$$

$$\text{COVERAGE}_r^j \in \mathbb{Z}^+ \quad \text{Required count: number of role } r \text{ needed for shift } j$$

$$h_{\max} \in \mathbb{R}^+ \quad \text{Max hours: maximum hours employee can work per week}$$

#### Coverage Constraints

For each shift $j$ and each required role $r$:

$$\sum_{i \in I} x_{i,j,r} = \text{COVERAGE}_r^j$$

**Interpretation:** Exactly the required number of employees must be assigned to each role for each shift.

#### Single Role Per Shift Constraint

For each employee $i$ and shift $j$:

$$\sum_{r \in R} x_{i,j,r} \leq 1$$

**Interpretation:** Employee can't work the same shift in multiple roles.

#### Availability Constraint

For each (i, j, r) pair where $A_{i,j} = 0$:

$$x_{i,j,r} = 0$$

**Implementation:** We enforce this by **not creating the variable in the first place** (pruning).

#### No Overlap Constraint

For each employee $i$ and overlapping shift pairs $(j, k)$:

$$\sum_{r \in R} x_{i,j,r} + \sum_{r \in R} x_{i,k,r} \leq 1$$

**Interpretation:** Employee can't be assigned to two shifts that overlap in time.

#### Max Hours Constraint

For each employee $i$:

$$\sum_{j \in J} \left( \sum_{r \in R} x_{i,j,r} \right) \cdot d_j \leq h_{\max}$$

**Interpretation:** Total hours worked across all shifts â‰¤ maximum allowed per week.

---

## 4. OPTIMIZATION TECHNIQUE: Branch and Bound (B&B)

### ğŸŒ³ How the Solver Finds the Optimal Solution

The MIP solver uses **Branch and Bound with Linear Relaxation**. This is how it avoids checking $2^{4000}$ combinations.

### Step 1: Linear Relaxation (Get an Upper Bound)

The solver first **relaxes** the binary constraint:

```
Original Problem (Integer):
  x[i,j,r] âˆˆ {0, 1}

Relaxed Problem (Continuous):
  x[i,j,r] âˆˆ [0.0, 1.0]
```

**Why?** Linear programs are **fast** to solve (milliseconds). Integer programs are **hard** (potentially exponential).

```python
# Solver's internal process:

# 1. Relax: treat x as continuous
relaxed_obj = solver.solve_linear_relaxation()
# 2. Check solution
if solution has fractional values (e.g., x[0,5,1] = 0.7):
    # Continue to branching
else:
    # All values are 0 or 1 â†’ Found integer solution!
    return solution
```

### Step 2: Branching (Split the Problem)

When the relaxation gives fractional values, the solver **branches** on one fractional variable:

```
Example: Relaxation gives x[0, 5, 1] = 0.7

Branch 1: Force x[0, 5, 1] = 0
  â””â”€ Solve relaxation again
     â””â”€ If obj < best_known â†’ Prune (explained below)
     â””â”€ If obj â‰¥ best_known and feasible â†’ May branch further

Branch 2: Force x[0, 5, 1] = 1
  â””â”€ Solve relaxation again
     â””â”€ Similar analysis
```

### Step 3: Pruning (The Key to Speed!)

**Pruning Rule:**

```
IF (Upper Bound of current branch) < (Best Feasible Solution Found) THEN
    PRUNE (stop exploring this branch)
    Reason: This branch can never beat the current best
```

### ğŸ¯ Concrete Example: Pruning in Action

```
Scheduling Problem:

Objective: Maximize preferences + fairness
Range: [0, 100] possible

Timeline:

1. Relax root node
   Upper Bound = 95
   (Not integer, so branch)

2. Branch on x[0, 5, 1]
   
   Left Branch (x[0,5,1] = 0):
     Upper Bound = 92
     (Still not integer, branch further)
     â””â”€ Sub-branch A: UB = 88, not integer
     â””â”€ Sub-branch B: UB = 87, not integer
     â””â”€ Sub-branch C: UB = 82, not integer
   
   Right Branch (x[0,5,1] = 1):
     Upper Bound = 91
     (Continue branching...)

3. Eventually find a feasible integer solution
   Found: Score = 85
   (This is our best_known)

4. Continue exploring other branches...

5. Encounter branch with UB = 84
   Compare: 84 < 85 (best_known)
   â†’ PRUNE! Stop exploring this branch
   Reason: Even if perfect inside, max is 84 < 85
   
   Time saved: 1000s of sub-nodes not explored!
```

### ğŸ“Š Why B&B Works for Our Problem

```
Without B&B:
  Check all 2^4000 combinations
  Time: IMPOSSIBLE (10^1000+ years)

With B&B + Pruning:
  Start: 2^4000 possible nodes
  After relaxation pruning: ~50% removed
  After feasibility pruning: ~70% removed
  After bound pruning: ~90% removed
  
  Actually explored nodes: ~4,000-10,000
  Time: 30-120 seconds âœ“
```

### ğŸ”§ How Our Code Uses B&B

```python
# From: backend/app/services/scheduling/mip_solver.py

model = mip.Model(sense=mip.MAXIMIZE, solver_name=mip.CBC)

# Configure Branch and Bound parameters
model.max_seconds = config.max_runtime_seconds      # 300 seconds
model.max_mip_gap = config.mip_gap                  # 5% gap allowed

# Solve (CBC solver uses B&B internally)
status = model.optimize()

# Results
if status == OPTIMAL:
    print(f"Found optimal with gap: {model.gap}")
elif status == FEASIBLE:
    print(f"Found feasible with gap: {model.gap}")
else:
    print("No solution found (infeasible)")
```

### ğŸ“ˆ The Trade-off: Optimality vs. Time

```
model.max_mip_gap = 0.0     â†’ Find absolute optimal (may take hours)
model.max_mip_gap = 0.05    â†’ Find solution within 5% of optimal (60s)
model.max_mip_gap = 0.20    â†’ Find solution within 20% of optimal (5s)

We choose: 0.05 (5% gap)
Reasoning: 5% difference in employee satisfaction is acceptable
           To save 4x runtime (from 5 min to 1 min)
```

---

## Summary: From Input to Solution

```
1. DATA PREPARATION
   â””â”€ OptimizationData: indices, matrices, parameters
   
2. PRUNING DECISION VARIABLES
   â””â”€ Create x[i,j,r] only for feasible (emp, shift, role)
   â””â”€ Reduce from 25,000 to ~4,000 variables
   
3. BUILD CONSTRAINTS
   â””â”€ Coverage, overlap, hours, rest periods
   
4. BUILD OBJECTIVE
   â””â”€ Maximize: preferences + fairness - violations
   
5. SOLVE WITH BRANCH & BOUND
   â””â”€ Linear relaxation for upper bounds
   â””â”€ Branching on fractional variables
   â””â”€ Pruning impossible branches
   â””â”€ Result: Feasible solution in 30-120 seconds
```

---
